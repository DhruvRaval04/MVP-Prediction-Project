{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pathlib as Path\n",
    "import os \n",
    "import glob\n",
    "##combines all the player stat mvps from 1960 - 2010 (training data)\n",
    "all_files = glob.glob(\"traincsvs/*.csv\")\n",
    "df_combinedcsv = pd.concat([pd.read_csv(f) for f in all_files], ignore_index = True)\n",
    "df_withdrop = df_combinedcsv.drop_duplicates(keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combines mvp list into one\n",
    "df_trainmvp = pd.concat(map(pd.read_csv, ['mvp.csv', 'mvp2.csv']), ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merges the mvp list with the statistics for the training data from 1960-2010\n",
    "df_finaltrain = pd.merge(df_withdrop, df_trainmvp, on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test data from 2010-2019 (includes mvp)\n",
    "df_testmvp = pd.read_csv('testmvp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combines test statistics from 2010-2019 \n",
    "all_testfiles = glob.glob(\"testcsvs/*.csv\")\n",
    "df_testcombinedcsv = pd.concat([pd.read_csv(f) for f in all_testfiles], ignore_index = True)\n",
    "df_testwithdrop = df_testcombinedcsv.drop_duplicates(keep='first', inplace=False, ignore_index=False)\n",
    "\n",
    "##merging the test data \n",
    "df_finaltest = pd.merge(df_testwithdrop, df_testmvp, on='Year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removing irrelevant columns in the dataset that do not affect if a player wins MVP - cleaning train data\n",
    "df_temptrain = df_finaltrain.drop(['Rk', 'Pos', 'Age', 'Tm', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT', 'FTA', '2P%', 'FT%',  ], axis=1)\n",
    "df_calculationstrain = df_temptrain.drop(['GS', 'DRB', 'ORB', 'PF'], axis=1)\n",
    "df_temptest = df_finaltest.drop(['Rk', 'Pos', 'Age', 'Tm', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT', 'FTA', '2P%', 'FT%',], axis=1)\n",
    "df_calculationstest = df_temptest.drop(['GS', 'DRB', 'ORB', 'PF'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removed all rows with letters instead of numbers \n",
    "df_calculationstrain = df_calculationstrain[df_calculationstrain.Player!='Player']\n",
    "df_calculationstest = df_calculationstest[df_calculationstest.Player!='Player']\n",
    "\n",
    "##replace all null values with 0 \n",
    "##null values exist because in the early years, some stats such as steals were not recorder by the NBA \n",
    "df_calculationstest = df_calculationstest.fillna(0)\n",
    "df_calculationstrain = df_calculationstrain.fillna(0)\n",
    "\n",
    "## remove * signs from players \n",
    "for i in range(len(df_calculationstrain.index)):\n",
    "    if (df_calculationstrain.iloc[i, 1]) [len(df_calculationstrain.iloc[i, 1]) - 1] == \"*\":\n",
    "        df_calculationstrain.iloc[i, 1] = (df_calculationstrain.iloc[i, 1]) [:-1]\n",
    "    \n",
    "for i in range(len(df_calculationstest.index)):\n",
    "    if (df_calculationstest.iloc[i, 1]) [len(df_calculationstest.iloc[i, 1]) - 1] == \"*\":\n",
    "        df_calculationstest.iloc[i, 1] = (df_calculationstest.iloc[i, 1]) [:-1]\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "##change the mvp coloumn from name to 0 or 1 to indicate a boolean MVP value (yes, he is the mvp if 1)\n",
    "df_calculationstrain['MVP'] = (df_calculationstrain['MVP'] == df_calculationstrain['Player']).astype(int)\n",
    "df_calculationstest['MVP'] = (df_calculationstest['MVP'] == df_calculationstest['Player']).astype(int)\n",
    "\n",
    "##useful to make another instance of the dataframe \n",
    "df_manual = df_calculationstest['Player']\n",
    "\n",
    "##dropping the player column and turning the data into one type \n",
    "df_calculationstrain = df_calculationstrain.drop('Player', axis=1)\n",
    "df_calculationstest = df_calculationstest.drop('Player', axis=1)\n",
    "\n",
    "df_calculationstrain = df_calculationstrain.astype(float)\n",
    "df_calculationstest = df_calculationstest.astype(float)\n",
    "\n",
    "df_calculationstrain = df_calculationstrain[df_calculationstrain.PTS > 10]\n",
    "df_calculationstest = df_calculationstest[df_calculationstest.PTS > 10]\n",
    "\n",
    "df_calculationstrain = df_calculationstrain[df_calculationstrain.G > 40]\n",
    "df_calculationstest = df_calculationstest[df_calculationstest.G > 40] \n",
    "\n",
    "df_modeltrain  = df_calculationstrain[df_calculationstrain.MP > 30]\n",
    "df_modeltest = df_calculationstest[df_calculationstest.MP > 30] \n",
    "\n",
    "##new df to keep track of player name \n",
    "df_tracktest = pd.concat([df_calculationstrain, df_manual], axis=1, join='inner')\n",
    "df_tracktest = df_tracktest.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 105, 213, 291, 380, 476, 559, 644, 724, 806]\n",
      "[0, 22, 46, 81, 112, 144, 175, 204, 240, 290, 351, 411, 472, 540, 608, 675, 738, 801, 871, 943, 1026, 1098, 1160, 1234, 1309, 1381, 1459, 1527, 1606, 1686, 1772, 1869, 1965, 2056, 2146, 2244, 2341, 2449, 2557, 2654, 2721, 2813, 2891, 2983, 3075, 3179, 3282, 3377, 3482, 3580]\n",
      "0.424\n"
     ]
    }
   ],
   "source": [
    "##checks to see where the year changes (since the amount of players per year differs)\n",
    "\n",
    "my_column_changestrain = df_modeltrain['Year'].shift() != df_modeltrain['Year']\n",
    "my_column_changestest = df_modeltest['Year'].shift() != df_modeltest['Year']\n",
    "\n",
    "my_column_changestrain = list(my_column_changestrain)\n",
    "my_column_changestest = list(my_column_changestest)\n",
    "\n",
    "listofyeartrain = []\n",
    "listofyeartest = []\n",
    "\n",
    "##creates a list which holds the indexes of when the year changes \n",
    "for i in range(len(my_column_changestrain)):\n",
    "    if my_column_changestrain[i]:\n",
    "        listofyeartrain.append(i)\n",
    "\n",
    "for i in range(len(my_column_changestest)):\n",
    "    if my_column_changestest[i]:\n",
    "        listofyeartest.append(i)\n",
    "\n",
    "\n",
    "##further cleaning the data \n",
    "df_modeltrain = df_modeltrain.drop(['Year', 'G', 'MP'], axis=1)\n",
    "df_modeltest = df_modeltest.drop(['Year', 'G', 'MP'], axis=1)\n",
    "\n",
    "##for understanding the final, cleaned data \n",
    "df_modeltrain.to_csv('train.csv')\n",
    "df_modeltest.to_csv('test.csv')\n",
    "\n",
    "##resetting the indexes\n",
    "df_modeltrain = df_modeltrain.reset_index(drop=True)\n",
    "df_modeltest = df_modeltest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887387387387387\n",
      "['Lebron James', 'Derrick Rose', 'LeBron James', 'LeBron James', 'Kevin Durant', 'Stephen Curry', 'Stephen Curry', 'Russell Westbrook', 'James Harden', 'Giannis Antetokounmpo']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "##implementing SGD classifier \n",
    "import sklearn \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train = df_modeltrain.drop(columns =['MVP'])\n",
    "Y_train = df_modeltrain['MVP']\n",
    "X_test = df_modeltest.drop(columns =['MVP'])\n",
    "Y_test = df_modeltest['MVP']\n",
    "\n",
    "##using logistic regression\n",
    "model1 = SGDClassifier(loss = 'log_loss', penalty='l1')\n",
    "\n",
    "##applying incremental learning onto each years dataset seperately \n",
    "for i in range(len(listofyeartrain)-1):\n",
    "    X_batch = X_train[listofyeartrain[i]:listofyeartrain[i+1]]\n",
    "    Y_batch = Y_train[listofyeartrain[i]:listofyeartrain[i+1]]\n",
    "\n",
    "    model1.partial_fit(X_batch,Y_batch, classes = np.unique(Y_batch))\n",
    "\n",
    "\n",
    "predictions = model1.predict(X_test)\n",
    "predictions = list(predictions)\n",
    "df_new = pd.DataFrame(predictions)\n",
    "\n",
    "score = accuracy_score(Y_test, predictions)\n",
    "\n",
    "##this accuracy is misrepresentative, as gains accuracy for not picking an mvp as well \n",
    "## since most of the players are not MVPs, this inflates the accuracy rate \n",
    "print(score)\n",
    "\n",
    "listtostore = []\n",
    "indexnum = 0\n",
    "\n",
    "##finding out what is predicted\n",
    "for i in range(len(predictions)):\n",
    "    indexnum = indexnum+1\n",
    "    if predictions[i] == 1:\n",
    "        listtostore.append(indexnum)\n",
    "        \n",
    "\n",
    "for i in range(len(listtostore)):\n",
    "    listtostore[i] = df_tracktest.iloc[listtostore[i], 13]\n",
    "\n",
    "##finding real accuracy \n",
    "listofactualmvps = ['Lebron James', 'Derrick Rose', 'LeBron James', 'LeBron James', 'Kevin Durant', 'Stephen Curry', 'Stephen Curry', 'Russell Westbrook', 'James Harden', 'Giannis Antetokounmpo']\n",
    "\n",
    "\n",
    "print(listofactualmvps)\n",
    "print(listtostore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887387387387387\n",
      "['Lebron James', 'Derrick Rose', 'LeBron James', 'LeBron James', 'Kevin Durant', 'Stephen Curry', 'Stephen Curry', 'Russell Westbrook', 'James Harden', 'Giannis Antetokounmpo']\n",
      "['Kwame Brown', 'Chris Duhon', 'Travis Outlaw', 'Ben Wallace', 'Earl Barron', 'Al Horford', 'Peja StojakoviÄ‡', 'Tyrus Thomas', 'Devin Ebanks', 'Armon Johnson', 'Kemba Walker', 'Reggie Williams', 'Lou Amundson', 'Jae Crowder', 'Andre Drummond', 'Blake Griffin', 'Grant Hill', 'John Lucas III', 'Josh McRoberts', 'Tim Ohlbrecht', 'Dexter Pittman']\n"
     ]
    }
   ],
   "source": [
    "##creating a decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "##use the MVP column as the Y \n",
    "X_train = df_modeltrain.drop(columns =['MVP'])\n",
    "Y_train = df_modeltrain['MVP']\n",
    "X_test = df_modeltest.drop(columns =['MVP'])\n",
    "Y_test = df_modeltest['MVP']\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "predictions2 = model.predict(X_test)\n",
    "score2 = accuracy_score(Y_test, predictions)\n",
    "##serves as a misrepresentation ^^ mentioned above \n",
    "print(score2)\n",
    "\n",
    "predictions2 = list(predictions2)\n",
    "\n",
    "\n",
    "df_new2 = pd.DataFrame(predictions2)\n",
    "\n",
    "\n",
    "\n",
    "listtostore2 = []\n",
    "indexnum2 = 0\n",
    "for i in range(len(predictions2)):\n",
    "    indexnum2 = indexnum2+1\n",
    "    if predictions2[i] == 1:\n",
    "        listtostore2.append(indexnum2)\n",
    "\n",
    "for i in range(len(listtostore2)):\n",
    "    listtostore2[i] = df_tracktest.iloc[listtostore2[i], 13]\n",
    "\n",
    "print(listofactualmvps)\n",
    "print(listtostore2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
